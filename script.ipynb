{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58b25ce",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install torch torchvision numpy scikit-learn matplotlib tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ee10e6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np, torch, torch.nn as nn, torch.optim as optim\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import trange\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e65ab0d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "In a standard GAN, we have:\n",
    " - A Generator (G) → creates fake data.\n",
    " - A Discriminator (D) → tries to tell real vs fake.\n",
    "\n",
    "In a Wasserstein GAN (WGAN):\n",
    " - The “Discriminator” is replaced by a Critic.\n",
    " - Instead of outputting probabilities (0 or 1 for fake/real),\n",
    "   it outputs a “realness score” (a real number).\n",
    " - The training objective tries to minimize the Wasserstein distance between real and fake data distributions.\n",
    "\n",
    "So this Critic learns a function C(x) that gives higher scores to real data and lower scores to fake data.\n",
    "'''\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, d):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(d, d//2), nn.LeakyReLU(0.01),\n",
    "            nn.Linear(d//2, d//3), nn.LeakyReLU(0.01),\n",
    "            nn.Linear(d//3, 1))\n",
    "    def forward(self,x): return self.net(x).view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78af65f1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim, d):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(z_dim, d+256), nn.BatchNorm1d(d+256), nn.LeakyReLU(0.01),\n",
    "            nn.Linear(d+256, d))\n",
    "    def forward(self,z): return self.net(z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6cd456",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def gradient_penalty(critic, real, fake, device):\n",
    "    eps = torch.rand(real.size(0),1, device=device)\n",
    "    interp = eps*real + (1-eps)*fake\n",
    "    interp.requires_grad_(True)\n",
    "    out = critic(interp)\n",
    "    grads = torch.autograd.grad(out, interp, torch.ones_like(out),\n",
    "                                create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    return ((grads.norm(2,dim=1)-1)**2).mean()*10.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d61c09",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def make_demo_data(n=600, m=1000):\n",
    "    rng=np.random.default_rng(0)\n",
    "    X=np.zeros((n,m))\n",
    "    for pop in range(3):\n",
    "        idx=slice(pop*(n//3),(pop+1)*(n//3))\n",
    "        freq=0.1+0.3*pop\n",
    "        f=freq+0.05*np.sin(np.linspace(0,15,m))\n",
    "        X[idx]=(rng.random((n//3,m))<f).astype(float)\n",
    "    return X.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ae5ef9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def train_pca_wgan(data, ncomp=0.9, epochs=300, batch=32, device='cuda'):\n",
    "    scaler=StandardScaler(with_std=False)\n",
    "    Xc=scaler.fit_transform(data)\n",
    "    pca=PCA(n_components=ncomp)\n",
    "    Z=pca.fit_transform(Xc).astype(np.float32)\n",
    "    d=Z.shape[1]; z_dim=max(512,d)\n",
    "    ds=DataLoader(TensorDataset(torch.tensor(Z)),batch_size=batch,shuffle=True,drop_last=True)\n",
    "    G, C = Generator(z_dim,d).to(device), Critic(d).to(device)\n",
    "    optG, optC = optim.RMSprop(G.parameters(),lr=1e-4), optim.RMSprop(C.parameters(),lr=8e-4)\n",
    "    for ep in trange(epochs):\n",
    "        for (x,) in ds:\n",
    "            x=x.to(device)\n",
    "            for _ in range(5):\n",
    "                z=torch.randn(batch,z_dim,device=device)\n",
    "                fake=G(z)\n",
    "                gp=gradient_penalty(C,x,fake,device)\n",
    "                lossC=(C(fake).mean()-C(x).mean())+gp\n",
    "                optC.zero_grad(); lossC.backward(); optC.step()\n",
    "            z=torch.randn(batch,z_dim,device=device)\n",
    "            lossG=-C(G(z)).mean()\n",
    "            optG.zero_grad(); lossG.backward(); optG.step()\n",
    "        if (ep+1)%50==0: print(f\"Epoch {ep+1}/{epochs} | lossC={lossC.item():.3f} | lossG={lossG.item():.3f}\")\n",
    "    # generate synthetic\n",
    "    with torch.no_grad():\n",
    "        z=torch.randn(data.shape[0],z_dim,device=device)\n",
    "        gen_scores=G(z).cpu().numpy()\n",
    "    recon=pca.inverse_transform(gen_scores)+scaler.mean_\n",
    "    synth=(recon>=0.5).astype(float)\n",
    "    return synth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7a88b6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ---------- Run demo ----------\n",
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "X=make_demo_data()\n",
    "print(\"Synthetic demo genotype matrix:\",X.shape)\n",
    "synth=train_pca_wgan(X, ncomp=0.9, epochs=300, device=device)\n",
    "np.save(\"synthetic_genotypes.npy\", synth)\n",
    "\n",
    "# ---------- Compare visually ----------\n",
    "p=PCA(2)\n",
    "proj_real=p.fit_transform(X)\n",
    "proj_synth=p.transform(synth)\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.scatter(proj_real[:,0],proj_real[:,1],s=5,alpha=.6,label='Real')\n",
    "plt.scatter(proj_synth[:,0],proj_synth[:,1],s=5,alpha=.6,label='Synthetic')\n",
    "plt.legend(); plt.title(\"PCA: Real vs Synthetic genomes\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
